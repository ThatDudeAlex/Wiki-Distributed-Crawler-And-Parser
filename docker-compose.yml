# TODO: adjust after crawler refactoring
x-crawler-common: &crawler-common
  build:
    context: .
    dockerfile: components/crawler/Dockerfile
  depends_on:
    # - postgres
    # - rabbitmq
    - redis
  env_file: .env
  command: [ "python", "-m", "components.crawler.main" ]
  volumes:
    - compressed_html_data:${DL_HTML_PATH}
  environment:
    - NO_PROXY=localhost,127.0.0.1,rabbitmq,redis,postgres,192.168.0.0/16

services:
  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    restart: unless-stopped
    env_file: .env
    ports:
      - "15672:15672"
      - "5672:5672"
    environment:
      RABBITMQ_DEFAULT_USER: "${RABBITMQ_USER}"
      RABBITMQ_DEFAULT_PASS: "${RABBITMQ_PASSWORD}"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq

  rabbitmq_seeder:
    container_name: rabbitmq_seeder
    build:
      context: .
      dockerfile: components/rabbitmq_seeder/Dockerfile
    env_file: .env
    depends_on:
      - rabbitmq
    command: [ "python", "-m", "components.rabbitmq_seeder.main" ]

  postgres:
    image: postgres:16
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: "${POSTGRES_DB}"
      POSTGRES_USER: "${POSTGRES_USER}"
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
      TZ: America/New_York
    volumes:
      - pg_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  pgadmin:
    image: dpage/pgadmin4:latest
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@domain.com
      PGADMIN_DEFAULT_PASSWORD: adminpassword
    ports:
      - "5050:80"
    depends_on:
      - postgres
    volumes:
      - pgadmin:/data/pgadmin

  postgres_initiator:
    container_name: postgres_initiator
    build:
      context: .
      dockerfile: components/postgres_initiator/Dockerfile
    depends_on:
      - postgres
    env_file: .env # Only used in local dev
    command: [ "python", "-m", "components.postgres_initiator.main" ]

  redis:
    image: redis:alpine
    container_name: redis
    restart: unless-stopped
    command: redis-server --maxmemory 2147483648 --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"

  # ============= 

  crawler_noproxy:
    <<: *crawler-common
    # California Proxies
  crawler_santa_cruz1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_SANTA_CRUZ1_PROXY}
      - HTTPS_PROXY=${CA_SANTA_CRUZ1_PROXY}

  crawler_santa_cruz2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_SANTA_CRUZ2_PROXY}
      - HTTPS_PROXY=${CA_SANTA_CRUZ2_PROXY}

  crawler_santa_clara:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_SANTA_CLARA_PROXY}
      - HTTPS_PROXY=${CA_SANTA_CLARA_PROXY}

  crawler_san_jose:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_SAN_JOSE_PROXY}
      - HTTPS_PROXY=${CA_SAN_JOSE_PROXY}

  crawler_la1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_LA1_PROXY}
      - HTTPS_PROXY=${CA_LA1_PROXY}

  crawler_la2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_LA2_PROXY}
      - HTTPS_PROXY=${CA_LA2_PROXY}

  crawler_la3:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_LA3_PROXY}
      - HTTPS_PROXY=${CA_LA3_PROXY}

  crawler_la4:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_LA4_PROXY}
      - HTTPS_PROXY=${CA_LA4_PROXY}

  crawler_la5:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_LA5_PROXY}
      - HTTPS_PROXY=${CA_LA5_PROXY}

  crawler_la6:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_LA6_PROXY}
      - HTTPS_PROXY=${CA_LA6_PROXY}

  crawler_la7:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_LA7_PROXY}
      - HTTPS_PROXY=${CA_LA7_PROXY}

  crawler_la8:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_LA8_PROXY}
      - HTTPS_PROXY=${CA_LA8_PROXY}

  crawler_la9:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_LA9_PROXY}
      - HTTPS_PROXY=${CA_LA9_PROXY}

  crawler_la10:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${CA_LA10_PROXY}
      - HTTPS_PROXY=${CA_LA10_PROXY}

  # Florida Proxies
  crawler_boca_raton:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${FL_BOCA_RATON_PROXY}
      - HTTPS_PROXY=${FL_BOCA_RATON_PROXY}

  # Kansas
  crawler_kansas_city:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${MO_KANSAS_CITY_PROXY}
      - HTTPS_PROXY=${MO_KANSAS_CITY_PROXY}

  # Louisiana
  crawler_abbeville:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${LA_ABBEVILLE_PROXY}
      - HTTPS_PROXY=${LA_ABBEVILLE_PROXY}

  # Nevada
  crawler_las_vegas1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NV_LAS_VEGAS1_PROXY}
      - HTTPS_PROXY=${NV_LAS_VEGAS1_PROXY}

  crawler_las_vegas2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NV_LAS_VEGAS2_PROXY}
      - HTTPS_PROXY=${NV_LAS_VEGAS2_PROXY}

  # New Jersey
  crawler_piscataway1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NJ_PISCATAWAY1_PROXY}
      - HTTPS_PROXY=${NJ_PISCATAWAY1_PROXY}

  crawler_piscataway2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NJ_PISCATAWAY2_PROXY}
      - HTTPS_PROXY=${NJ_PISCATAWAY2_PROXY}

  crawler_piscataway3:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NJ_PISCATAWAY3_PROXY}
      - HTTPS_PROXY=${NJ_PISCATAWAY3_PROXY}

  # New York
  crawler_buffalo1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_BUFFALO1_PROXY}
      - HTTPS_PROXY=${NY_BUFFALO1_PROXY}

  crawler_buffalo2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_BUFFALO2_PROXY}
      - HTTPS_PROXY=${NY_BUFFALO2_PROXY}

  crawler_buffalo3:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_BUFFALO3_PROXY}
      - HTTPS_PROXY=${NY_BUFFALO3_PROXY}

  crawler_buffalo4:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_BUFFALO4_PROXY}
      - HTTPS_PROXY=${NY_BUFFALO4_PROXY}

  crawler_buffalo5:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_BUFFALO5_PROXY}
      - HTTPS_PROXY=${NY_BUFFALO5_PROXY}

  crawler_nyc1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_NEW_YORK1_PROXY}
      - HTTPS_PROXY=${NY_NEW_YORK1_PROXY}

  crawler_nyc2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_NEW_YORK2_PROXY}
      - HTTPS_PROXY=${NY_NEW_YORK2_PROXY}

  crawler_nyc3:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_NEW_YORK3_PROXY}
      - HTTPS_PROXY=${NY_NEW_YORK3_PROXY}

  crawler_nyc4:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_NEW_YORK4_PROXY}
      - HTTPS_PROXY=${NY_NEW_YORK4_PROXY}

  crawler_nyc5:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_NEW_YORK5_PROXY}
      - HTTPS_PROXY=${NY_NEW_YORK5_PROXY}

  crawler_nyc6:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_NEW_YORK6_PROXY}
      - HTTPS_PROXY=${NY_NEW_YORK6_PROXY}

  crawler_nyc7:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${NY_NEW_YORK7_PROXY}
      - HTTPS_PROXY=${NY_NEW_YORK7_PROXY}

  # Texas Proxies
  crawler_dallas1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${TX_DALLAS1_PROXY}
      - HTTPS_PROXY=${TX_DALLAS1_PROXY}

  crawler_dallas2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${TX_DALLAS2_PROXY}
      - HTTPS_PROXY=${TX_DALLAS2_PROXY}

  crawler_victoria1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${TX_VICTORIA1_PROXY}
      - HTTPS_PROXY=${TX_VICTORIA1_PROXY}

  crawler_victoria2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${TX_VICTORIA2_PROXY}
      - HTTPS_PROXY=${TX_VICTORIA2_PROXY}

  crawler_victoria3:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${TX_VICTORIA3_PROXY}
      - HTTPS_PROXY=${TX_VICTORIA3_PROXY}

  # Utah

  crawler_orem1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${UT_OREM1_PROXY}
      - HTTPS_PROXY=${UT_OREM1_PROXY}

  crawler_orem2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${UT_OREM2_PROXY}
      - HTTPS_PROXY=${UT_OREM2_PROXY}

  # Virginia Proxies
  crawler_ashburn1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${VA_ASHBURN1_PROXY}
      - HTTPS_PROXY=${VA_ASHBURN1_PROXY}

  crawler_ashburn2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${VA_ASHBURN2_PROXY}
      - HTTPS_PROXY=${VA_ASHBURN2_PROXY}

  crawler_ashburn3:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${VA_ASHBURN3_PROXY}
      - HTTPS_PROXY=${VA_ASHBURN3_PROXY}

  crawler_ashburn4:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${VA_ASHBURN4_PROXY}
      - HTTPS_PROXY=${VA_ASHBURN4_PROXY}

  crawler_reston1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${VA_RESTON1_PROXY}
      - HTTPS_PROXY=${VA_RESTON1_PROXY}

  crawler_reston2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${VA_RESTON2_PROXY}
      - HTTPS_PROXY=${VA_RESTON2_PROXY}

  crawler_reston3:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${VA_RESTON3_PROXY}
      - HTTPS_PROXY=${VA_RESTON3_PROXY}

  # Washington DC
  crawler_dc1:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${DC_WASHINGTON1_PROXY}
      - HTTPS_PROXY=${DC_WASHINGTON1_PROXY}

  crawler_dc2:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${DC_WASHINGTON2_PROXY}
      - HTTPS_PROXY=${DC_WASHINGTON2_PROXY}

  crawler_dc3:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${DC_WASHINGTON3_PROXY}
      - HTTPS_PROXY=${DC_WASHINGTON3_PROXY}

  crawler_dc4:
    <<: *crawler-common
    environment:
      - HTTP_PROXY=${DC_WASHINGTON4_PROXY}
      - HTTPS_PROXY=${DC_WASHINGTON4_PROXY}

  # =========== 

  parser:
    build:
      context: .
      dockerfile: components/parser/Dockerfile
    depends_on:
      - postgres
      - rabbitmq
    env_file: .env
    command: [ "python", "-m", "components.parser.main" ]
    volumes:
      - compressed_html_data:${DL_HTML_PATH}

  db_writer:
    # container_name: db_writer
    build:
      context: .
      dockerfile: components/db_writer/Dockerfile
    env_file: .env
    depends_on:
      - postgres
    command: [ "python", "-m", "components.db_writer.main" ]

  db_reader:
    container_name: db_reader
    build:
      context: .
      dockerfile: components/db_reader/Dockerfile
    env_file: .env
    ports:
      - "8001:8001"
    depends_on:
      - postgres
    command: [ "python", "-m", "components.db_reader.main" ]

  scheduler:
    # container_name: scheduler
    build:
      context: .
      dockerfile: components/scheduler/Dockerfile
    env_file: .env
    depends_on:
      - rabbitmq
      - postgres
    environment:
      - DB_READER_HOST=${DB_READER_HOST}
    command: [ "python", "-m", "components.scheduler.main" ]

  dispatcher:
    container_name: dispatcher
    build:
      context: .
      dockerfile: components/dispatcher/Dockerfile
    env_file: .env
    depends_on:
      - rabbitmq
      - postgres
      - db_reader
    environment:
      - DB_READER_HOST=${DB_READER_HOST}
    command: [ "python", "-m", "components.dispatcher.main" ]

volumes:
  pg_data:
  pgadmin:
  compressed_html_data:
  rabbitmq_data:
    driver: local
